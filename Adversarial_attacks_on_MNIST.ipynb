{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial attacks on MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQX+21m8lc6S2zh1oTrBqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaLanzillotta/exercises/blob/master/Adversarial_attacks_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV1lcyF1W7NC"
      },
      "source": [
        "# Adversarial attacks on MNIST\n",
        "\n",
        "Today we're going to do 2 things: \n",
        "- Traine a naive CNN on MNIST\n",
        "- Attack it with different techniques\n",
        "\n",
        "Let's start!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIYOGHD-YOYF"
      },
      "source": [
        "# uncomment if not already installed  \n",
        "# !pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B2QCeWTXtA4",
        "outputId": "94fee4dc-327a-4877-b6b5-7e0bb636b8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Imports + constants\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility \n",
        "# Notice that complete reproducibility is not guaranteed anyway \n",
        "# (for example due to the non perfect associativity of floating point addition)\n",
        "# Look here for more : https://pytorch.org/docs/stable/notes/randomness.html\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f78b74c65a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a0LqBJ0XfMA"
      },
      "source": [
        "## MNIST classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG5HZqtSZHSO"
      },
      "source": [
        "### The architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffWO65hoWxMo"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"2 layers feed-forward classifier for MNIST images\"\"\"\n",
        "  def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = x.view((-1, 28*28))\n",
        "      x = F.relu(self.fc(x))\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYohHAM5Zu9Y"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  \"\"\"Pretty basic CNN classifier for MNIST images.\"\"\"\n",
        "  def __init__(self):\n",
        "      # We'll use 6 convolutional layers with decreasing convolution window \n",
        "      # and increasing number of channels \n",
        "      # + ReLU after each layer \n",
        "      # + batch normalization\n",
        "      # + dropout and 2 fully connected layers as a classification head \n",
        "      super(ConvNet, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5))\n",
        "      self.bn1 = nn.BatchNorm2d(32)\n",
        "      self.conv2 = nn.Conv2d(32, 32, kernel_size=(5, 5))\n",
        "      self.bn2 = nn.BatchNorm2d(32)\n",
        "      self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
        "      self.bn3 = nn.BatchNorm2d(64)\n",
        "      self.conv4 = nn.Conv2d(64, 64, kernel_size=(3, 3))\n",
        "      self.bn4 = nn.BatchNorm2d(64)\n",
        "      self.conv5 = nn.Conv2d(64, 128, kernel_size=(3, 3))\n",
        "      self.bn5 = nn.BatchNorm2d(128)\n",
        "      self.conv6 = nn.Conv2d(128, 128, kernel_size=(1, 1))\n",
        "      self.bn6 = nn.BatchNorm2d(128)\n",
        "      self.conv2_drop = nn.Dropout2d(p=0.2)\n",
        "      self.fc1 = nn.Linear(128, 100)\n",
        "      self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      ##  CONVOLUTIONAL LAYERS \n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = self.bn1(x)\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = self.conv2_drop(F.max_pool2d(self.bn2(x), 2))\n",
        "      x = F.relu(self.conv3(x))\n",
        "      x = self.bn3(x)\n",
        "      x = F.relu(self.conv4(x))\n",
        "      x = self.bn4(x)\n",
        "      x = F.max_pool2d(x, 2)\n",
        "      x = self.conv2_drop(x)\n",
        "      x = F.relu(self.conv5(x))\n",
        "      x = self.bn5(x)\n",
        "      x = F.relu(self.conv6(x))\n",
        "      x = self.bn6(x)\n",
        "      ## CLASSIFICATION HEAD \n",
        "      size = x.size()[1] * x.size()[2] * x.size()[3]\n",
        "      # flattening \n",
        "      x = x.view(-1, size)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      return x\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nEnzUryZJyu"
      },
      "source": [
        "### The data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7RBlTLCZMQI"
      },
      "source": [
        "# Here do 2 things: \n",
        "# 1. Download the MNIST dataset (already divided into train and test)\n",
        "# 2. normalize the input s.t. we have a certain mean and sd \n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o1ci2cDcpIc"
      },
      "source": [
        "# Use a DataLoader to avoid iterating through the data yourself\n",
        "# Notice the batch_size=64 that we defined above \n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvrpr-PKZMhM"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l4njkbmc2t4",
        "outputId": "c5ff4d42-7dbb-4458-f4c0-782787480b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# (This has any effect only if the model is not already there)\n",
        "model = Net().to(device)\n",
        "\n",
        "#This has any effect only on certain modules\n",
        "# (e.g. Dropout, BatchNorm) which behave differently \n",
        "# in train and test mode.\n",
        "model.train()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc): Linear(in_features=784, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r55wbv2rZM35"
      },
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 20\n",
        "# Optimizers:\n",
        "\"\"\" SGD vs Adam \"\"\"\n",
        "#opt = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
        "opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "# Loss: \n",
        "ce_loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgwHF22UdOjs",
        "outputId": "6952ade4-d2ca-4cb9-cc87-77508efbe6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "tot_steps = 0\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  print(\"-------------- Epoch \"+str(epoch)+\"-------------\")\n",
        "  t1 = time.time()\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    tot_steps += 1\n",
        "    opt.zero_grad()\n",
        "    out = model(x_batch)\n",
        "    batch_loss = ce_loss(out, y_batch)\n",
        "\n",
        "    # show accuracy every 100 steps\n",
        "    if batch_idx % 100 == 0:\n",
        "      pred = torch.max(out, dim=1)[1] # predictions\n",
        "      acc = pred.eq(y_batch).sum().item() / float(batch_size) # accuracy\n",
        "      print(\"Batch \"+str(batch_idx)+\": \"+ str(acc))\n",
        "\n",
        "    batch_loss.backward()\n",
        "    opt.step() \n",
        "  t2 = time.time()\n",
        "  print(\"Time = %.2lf seconds\"%(t2-t1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-8513c0f35195>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print(\"Time = %.2lf seconds\",%(t2-t1))\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ1kXDiFeP3U"
      },
      "source": [
        "# Evaluate on the test set \n",
        "tot_test, tot_acc = 0.0, 0.0\n",
        "for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    pred = torch.max(out, dim=1)[1]\n",
        "    acc = pred.eq(y_batch).sum().item()\n",
        "    tot_acc += acc\n",
        "    tot_test += x_batch.size()[0]\n",
        "print('Accuracy %.5lf ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy7kacRpXhkA"
      },
      "source": [
        "## Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ew0qQPjXr7y"
      },
      "source": [
        "# loading the dataset\n",
        "# note that this time we do not perfrom the normalization operation, see next cell\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLRNDCXcf-7t"
      },
      "source": [
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# we load the body of the neural net trained with mnist_train.ipynb...\n",
        "model = torch.load('model.net', map_location='cpu') \n",
        "\n",
        "# ... and add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "model = nn.Sequential(Normalize(), model)\n",
        "\n",
        "# and here we also create a version of the model that outputs the class probabilities\n",
        "model_to_prob = nn.Sequential(model, nn.Softmax())\n",
        "\n",
        "# we put the neural net into evaluation mode (this disables features like dropout)\n",
        "model.eval()\n",
        "model_to_prob.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PhkBBzqgBal"
      },
      "source": [
        "# define a show function for later\n",
        "def show(original, adv, model_to_prob):\n",
        "    p0 = model_to_prob(original).detach().numpy()\n",
        "    p1 = model_to_prob(adv).detach().numpy()\n",
        "    f, axarr = plt.subplots(1,2)\n",
        "    axarr[0].imshow(original.detach().numpy().reshape(28, 28), cmap='gray')\n",
        "    axarr[0].set_title(\"Original, class: \" + str(p0.argmax()))\n",
        "    axarr[1].imshow(adv.detach().numpy().reshape(28, 28), cmap='gray')\n",
        "    axarr[1].set_title(\"Original, class: \" + str(p1.argmax()))\n",
        "    print(\"Class\\t\\tOrig\\tAdv\")\n",
        "    for i in range(10):\n",
        "        print(\"Class {}:\\t{:.2f}\\t{:.2f}\".format(i, float(p0[:, i]), float(p1[:, i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddvlDufgEPG"
      },
      "source": [
        "def fgsm_targeted(model, x, target, eps):\n",
        "    # TODO: implement\n",
        "    return x\n",
        "\n",
        "def fgsm_untargeted(model, x, label, eps):\n",
        "    # TODO: implement\n",
        "    return x\n",
        "\n",
        "def pgd_targeted(model, x, target, k, eps, eps_step):\n",
        "    # TODO: implement\n",
        "    return x\n",
        "\n",
        "def pgd_untargeted(model, x, label, k, eps, eps_step):\n",
        "    # TODO: implement\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUVVUNLHgF0M"
      },
      "source": [
        "# try out our attacks\n",
        "original = torch.unsqueeze(test_dataset[0][0], dim=0)\n",
        "adv = pgd_untargeted(model, original, 7, 10, 0.08, 0.05, clip_min=0, clip_max=1.0)\n",
        "show(original, adv, model_to_prob)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial attacks on MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYD0/gIVU4RXXUja+WTSOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiuliaLanzillotta/exercises/blob/master/Adversarial_attacks_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV1lcyF1W7NC"
      },
      "source": [
        "# Adversarial attacks on MNIST\n",
        "\n",
        "Today we're going to do 2 things: \n",
        "- Traine a naive CNN on MNIST\n",
        "- Attack it with different techniques\n",
        "\n",
        "Let's start!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIYOGHD-YOYF"
      },
      "source": [
        "# uncomment if not already installed  \n",
        "#!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B2QCeWTXtA4",
        "outputId": "48aeb817-de8a-45ed-fe44-bdd6503919c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Imports + constants\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility \n",
        "# Notice that complete reproducibility is not guaranteed anyway \n",
        "# (for example due to the non perfect associativity of floating point addition)\n",
        "# Look here for more : https://pytorch.org/docs/stable/notes/randomness.html\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2d7d8685e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a0LqBJ0XfMA"
      },
      "source": [
        "## MNIST classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG5HZqtSZHSO"
      },
      "source": [
        "### The architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffWO65hoWxMo"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  \"\"\"2 layers feed-forward classifier for MNIST images\"\"\"\n",
        "  def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = x.view((-1, 28*28))\n",
        "      x = F.relu(self.fc(x))\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYohHAM5Zu9Y"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  \"\"\"Pretty basic CNN classifier for MNIST images.\"\"\"\n",
        "  def __init__(self):\n",
        "      # We'll use 6 convolutional layers with decreasing convolution window \n",
        "      # and increasing number of channels \n",
        "      # + ReLU after each layer \n",
        "      # + batch normalization\n",
        "      # + dropout and 2 fully connected layers as a classification head \n",
        "      super(ConvNet, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(1, 32, kernel_size=(5, 5))\n",
        "      self.bn1 = nn.BatchNorm2d(32)\n",
        "      self.conv2 = nn.Conv2d(32, 32, kernel_size=(5, 5))\n",
        "      self.bn2 = nn.BatchNorm2d(32)\n",
        "      self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3))\n",
        "      self.bn3 = nn.BatchNorm2d(64)\n",
        "      self.conv4 = nn.Conv2d(64, 64, kernel_size=(3, 3))\n",
        "      self.bn4 = nn.BatchNorm2d(64)\n",
        "      self.conv5 = nn.Conv2d(64, 128, kernel_size=(3, 3))\n",
        "      self.bn5 = nn.BatchNorm2d(128)\n",
        "      self.conv6 = nn.Conv2d(128, 128, kernel_size=(1, 1))\n",
        "      self.bn6 = nn.BatchNorm2d(128)\n",
        "      self.conv2_drop = nn.Dropout2d(p=0.2)\n",
        "      self.fc1 = nn.Linear(128, 100)\n",
        "      self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      ##  CONVOLUTIONAL LAYERS \n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = self.bn1(x)\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = self.conv2_drop(F.max_pool2d(self.bn2(x), 2))\n",
        "      x = F.relu(self.conv3(x))\n",
        "      x = self.bn3(x)\n",
        "      x = F.relu(self.conv4(x))\n",
        "      x = self.bn4(x)\n",
        "      x = F.max_pool2d(x, 2)\n",
        "      x = self.conv2_drop(x)\n",
        "      x = F.relu(self.conv5(x))\n",
        "      x = self.bn5(x)\n",
        "      x = F.relu(self.conv6(x))\n",
        "      x = self.bn6(x)\n",
        "      ## CLASSIFICATION HEAD \n",
        "      size = x.size()[1] * x.size()[2] * x.size()[3]\n",
        "      # flattening \n",
        "      x = x.view(-1, size)\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.fc2(x)\n",
        "      return x\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nEnzUryZJyu"
      },
      "source": [
        "### The data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7RBlTLCZMQI"
      },
      "source": [
        "# Here do 2 things: \n",
        "# 1. Download the MNIST dataset (already divided into train and test)\n",
        "# 2. normalize the input s.t. we have a certain mean and sd (note that the provided\n",
        "# mean and sd are the empirical ones from the data)\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, \n",
        "                               transform=transforms.Compose([transforms.ToTensor(), \n",
        "                                                             transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, \n",
        "                              transform=transforms.Compose([transforms.ToTensor(), \n",
        "                                                            transforms.Normalize((0.1307,), (0.3081,))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o1ci2cDcpIc"
      },
      "source": [
        "# Use a DataLoader to avoid iterating through the data yourself\n",
        "# Notice the batch_size=64 that we defined above \n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvrpr-PKZMhM"
      },
      "source": [
        "### Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l4njkbmc2t4",
        "outputId": "3b57c915-bb8d-44e6-993b-b7d7e4d7b851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# (This has any effect only if the model is not already there)\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "#This has any effect only on certain modules\n",
        "# (e.g. Dropout, BatchNorm) which behave differently \n",
        "# in train and test mode.\n",
        "model.train()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2_drop): Dropout2d(p=0.2, inplace=False)\n",
              "  (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r55wbv2rZM35"
      },
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 5\n",
        "# Optimizers:\n",
        "\"\"\" SGD vs Adam \"\"\"\n",
        "#opt = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
        "opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "# Loss: \n",
        "ce_loss = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgwHF22UdOjs",
        "outputId": "e8925170-f034-4d76-9ca9-c31ddcb79ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tot_steps = 0\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  print(\"-------------- Epoch \"+str(epoch)+\" -------------\")\n",
        "  t1 = time.time()\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    tot_steps += 1\n",
        "    opt.zero_grad()\n",
        "    out = model(x_batch)\n",
        "    batch_loss = ce_loss(out, y_batch)\n",
        "\n",
        "    # show accuracy every 100 steps\n",
        "    if batch_idx % 100 == 0:\n",
        "      pred = torch.max(out, dim=1)[1] # predictions\n",
        "      acc = pred.eq(y_batch).sum().item() / float(batch_size) # accuracy\n",
        "      print(\"Batch \"+str(batch_idx)+\": \"+ str(acc))\n",
        "\n",
        "    batch_loss.backward()\n",
        "    opt.step() \n",
        "  t2 = time.time()\n",
        "  print(\"Time = %.2lf seconds\"%(t2-t1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------- Epoch 1 -------------\n",
            "Batch 0: 0.15625\n",
            "Batch 100: 0.703125\n",
            "Batch 200: 0.953125\n",
            "Batch 300: 0.921875\n",
            "Batch 400: 0.921875\n",
            "Batch 500: 0.96875\n",
            "Batch 600: 0.96875\n",
            "Batch 700: 0.96875\n",
            "Batch 800: 0.96875\n",
            "Batch 900: 1.0\n",
            "Time = 172.04 seconds\n",
            "-------------- Epoch 2 -------------\n",
            "Batch 0: 1.0\n",
            "Batch 100: 0.953125\n",
            "Batch 200: 0.953125\n",
            "Batch 300: 0.984375\n",
            "Batch 400: 0.984375\n",
            "Batch 500: 0.96875\n",
            "Batch 600: 0.984375\n",
            "Batch 700: 0.984375\n",
            "Batch 800: 0.96875\n",
            "Batch 900: 1.0\n",
            "Time = 172.28 seconds\n",
            "-------------- Epoch 3 -------------\n",
            "Batch 0: 0.984375\n",
            "Batch 100: 1.0\n",
            "Batch 200: 0.984375\n",
            "Batch 300: 0.96875\n",
            "Batch 400: 1.0\n",
            "Batch 500: 1.0\n",
            "Batch 600: 0.96875\n",
            "Batch 700: 0.984375\n",
            "Batch 800: 0.96875\n",
            "Batch 900: 1.0\n",
            "Time = 172.63 seconds\n",
            "-------------- Epoch 4 -------------\n",
            "Batch 0: 1.0\n",
            "Batch 100: 0.984375\n",
            "Batch 200: 1.0\n",
            "Batch 300: 0.984375\n",
            "Batch 400: 1.0\n",
            "Batch 500: 0.984375\n",
            "Batch 600: 0.984375\n",
            "Batch 700: 1.0\n",
            "Batch 800: 0.984375\n",
            "Batch 900: 0.96875\n",
            "Time = 172.82 seconds\n",
            "-------------- Epoch 5 -------------\n",
            "Batch 0: 1.0\n",
            "Batch 100: 1.0\n",
            "Batch 200: 0.984375\n",
            "Batch 300: 0.96875\n",
            "Batch 400: 0.96875\n",
            "Batch 500: 0.984375\n",
            "Batch 600: 0.96875\n",
            "Batch 700: 1.0\n",
            "Batch 800: 1.0\n",
            "Batch 900: 1.0\n",
            "Time = 172.62 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ1kXDiFeP3U",
        "outputId": "e8d9eec3-d5ef-4aeb-ba89-5f935558bb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Evaluate on the test set \n",
        "tot_test, tot_acc = 0.0, 0.0\n",
        "for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    pred = torch.max(out, dim=1)[1]\n",
        "    acc = pred.eq(y_batch).sum().item()\n",
        "    tot_acc += acc\n",
        "    tot_test += x_batch.size()[0]\n",
        "acc = tot_acc/tot_test\n",
        "print('Accuracy %.5lf'%(acc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.98870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oFGmjJkQkpU"
      },
      "source": [
        "Here I'll save the result of some trials:\n",
        "\n",
        "    1) Net + Adam x 5 epochs = 0.9575 test accuracy / time x epoch around 11 s\n",
        "    2) ConvNet + Adam x 5 epochs = 0.98870 test accuracy/ time x epoch around 170 s\n",
        "\n",
        "Notice that this result are obtained by training on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy7kacRpXhkA"
      },
      "source": [
        "## Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ew0qQPjXr7y",
        "outputId": "0301422e-0169-443c-eaff-0f7afad6313d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# We first load the test dataset again. \n",
        "# Notice that this time we don't want to normalize the input right away \n",
        "# (as we want to be able to search for adversarial examples in the original \n",
        "# image domain)\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, \n",
        "                              transform=transforms.Compose([transforms.ToTensor()]))\n",
        "# In order to be able for our trained model to function with this un-normalized\n",
        "# input we need to insert a normalization layer first \n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "model = nn.Sequential(Normalize(), model)\n",
        "# and here we also create a version of the model that outputs the class probabilities\n",
        "model_to_prob = nn.Sequential(model, nn.Softmax())\n",
        "# we put the neural net into evaluation mode (this disables features like dropout)\n",
        "model.eval()\n",
        "model_to_prob.eval()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Normalize()\n",
              "    (1): ConvNet(\n",
              "      (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_drop): Dropout2d(p=0.2, inplace=False)\n",
              "      (fc1): Linear(in_features=128, out_features=100, bias=True)\n",
              "      (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (1): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGY0oZO_SqxR"
      },
      "source": [
        "#### The attacks \n",
        "We're now going to implement 4 different attacks (actually 2, each one of them in its targeted and untargeted version). \n",
        "\n",
        "1) **FGSM** : fast gradient sign method. One shot algorithm, meaning that the output is obtained in only one step. \n",
        "\n",
        "2) **PGD** : projected gradient descent (method) - an iterative evolution of the previous one\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CddvlDufgEPG"
      },
      "source": [
        "def fgsm_targeted(model, x, target, eps):\n",
        "    # The idea here is to minimise the model's loss \n",
        "    # with respect to the target label \n",
        "\n",
        "    # tell pytorch to track the gradients wrt input x\n",
        "    x.requires_grad = True \n",
        "    # loss here \n",
        "    loss = ce_loss(model(x), torch.tensor([target], dtype=torch.long))\n",
        "    # gradient of the loss \n",
        "    loss.backward() \n",
        "    # get adversarial example \n",
        "    x_adv = x - eps*torch.sign(x.grad)\n",
        "    return x_adv\n",
        "\n",
        "def fgsm_untargeted(model, x, label, eps):\n",
        "    # The idea here is to maximise the model's loss wrt \n",
        "    # the original label ('label')\n",
        "\n",
        "    # tell pytorch to track the gradients wrt input x\n",
        "    x.requires_grad = True \n",
        "    # loss here \n",
        "    loss = ce_loss(model(x), torch.tensor([label], dtype=torch.long))\n",
        "    # gradient of the loss \n",
        "    loss.backward() \n",
        "    # get adversarial example \n",
        "    x_adv = x + eps*torch.sign(x.grad)\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "def pgd_targeted(model, x, target, k, eps, eps_step):\n",
        "    # The idea here is to search for adversarial example \n",
        "    # inside a ball around the original example x \n",
        "    # As projection is easier in this case, we use an L-infinity \n",
        "    # ball of radius eps \n",
        "    # Moreover we restrict the outputs to the [0,1]^n box \n",
        "    x.requires_grad = True \n",
        "    # random initialization \n",
        "    eta = torch.rand(size=x.size())*2*eps - eps\n",
        "    x = x + eta\n",
        "    # iteration \n",
        "    for steps in range(1,k+1):\n",
        "      loss = ce_loss(model(x), torch.tensor([target], dtype=torch.long))\n",
        "      loss.backward() \n",
        "      # projecting the step\n",
        "      delta = eps_step*torch.sign(x.grad)\n",
        "      delta = torch.clamp(delta, min=-1*eps, max=eps)  \n",
        "      # taking the step    \n",
        "      x = x - delta\n",
        "      # projecting the output to the [0,1] box\n",
        "      x = torch.clamp(x, min=0, max=1)\n",
        "      # check if we have an adversarial example \n",
        "      out = model(x)\n",
        "      pred = torch.max(out, dim=1)\n",
        "      if pred==target: return x\n",
        "\n",
        "    return x\n",
        "\n",
        "def pgd_untargeted(model, x, label, k, eps, eps_step):\n",
        "  # Same as above with the only difference that we're now \n",
        "  # maximising the loss wrt the correct label \n",
        "  x.requires_grad = True \n",
        "  # random initialization \n",
        "  eta = torch.rand(size=x.size())*2*eps - eps\n",
        "  x = x + eta\n",
        "  # iteration \n",
        "  for steps in range(1,k+1):\n",
        "    loss = ce_loss(model(x), torch.tensor([label], dtype=torch.long))\n",
        "    loss.backward() \n",
        "    # projecting the step\n",
        "    delta = eps_step*torch.sign(x.grad)\n",
        "    delta = torch.clamp(delta, min=-1*eps, max=eps)  \n",
        "    # taking the step    \n",
        "    x = x + delta\n",
        "    # projecting the output to the [0,1] box\n",
        "    x = torch.clamp(x, min=0, max=1)\n",
        "    # check if we have an adversarial example \n",
        "    out = model(x)\n",
        "    pred = torch.max(out, dim=1)\n",
        "    if pred!=label: return x\n",
        "\n",
        "  return x"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PhkBBzqgBal"
      },
      "source": [
        "# define a show function that displays the original image together with the \n",
        "# adversarial example and the model predictions\n",
        "def show(original, adv, model_to_prob):\n",
        "    p0 = model_to_prob(original).detach().numpy()\n",
        "    p1 = model_to_prob(adv).detach().numpy()\n",
        "    f, axarr = plt.subplots(1,2)\n",
        "    axarr[0].imshow(original.detach().numpy().reshape(28, 28), cmap='gray')\n",
        "    axarr[0].set_title(\"Original, class: \" + str(p0.argmax()))\n",
        "    axarr[1].imshow(adv.detach().numpy().reshape(28, 28), cmap='gray')\n",
        "    axarr[1].set_title(\"Original, class: \" + str(p1.argmax()))\n",
        "    print(\"Class\\t\\tOrig\\tAdv\")\n",
        "    for i in range(10):\n",
        "        print(\"Class {}:\\t{:.2f}\\t{:.2f}\".format(i, float(p0[:, i]), float(p1[:, i])))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUVVUNLHgF0M",
        "outputId": "efe68f80-5f94-4954-bd5a-16a7cf0afeb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "# try out our attacks\n",
        "original = torch.unsqueeze(test_dataset[0][0], dim=0)\n",
        "adv = pgd_untargeted(model, original, 7, 10, 0.08, 0.05)\n",
        "show(original, adv, model_to_prob)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-09a6cacf8cc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try out our attacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_untargeted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_to_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-aef1f10713f2>\u001b[0m in \u001b[0;36mpgd_untargeted\u001b[0;34m(model, x, label, k, eps, eps_step)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# projecting the step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meps_step\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# taking the step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sign(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbDikad7c15-",
        "outputId": "73b50ea8-9ca5-4f24-f1ae-09bdbdf69304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "original.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd9v_ThMa2av"
      },
      "source": [
        "x = original\n",
        "eps = 0.05\n",
        "opt.zero_grad()\n",
        "x.requires_grad = True \n",
        "# random initialization \n",
        "eta = torch.rand(size=x.size())*2*eps - eps\n",
        "x = x + eta\n",
        "# iteration \n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usmgZZWlbdU0"
      },
      "source": [
        "label = 7\n",
        "loss = ce_loss(model(x), torch.tensor([label], dtype=torch.long))\n",
        "loss.backward() \n",
        "\n",
        "eps_step = 0.008\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7aBY5PSbvNN",
        "outputId": "0390a9e1-1231-4c36-f4fd-03ac0fe0bd61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x.retain_grad"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Tensor.retain_grad of tensor([[[[ 4.4875e-02,  9.4602e-03, -1.6144e-02, -3.2048e-02,  2.4450e-02,\n",
              "            3.7579e-02,  4.6515e-02, -4.3480e-02, -1.4027e-02,  2.4049e-02,\n",
              "           -1.4525e-02, -2.5734e-03, -9.7045e-03,  3.2777e-02, -9.0880e-03,\n",
              "           -3.0407e-02,  4.0199e-02,  1.9781e-02,  1.6227e-03, -4.7843e-02,\n",
              "            3.3347e-02,  2.7913e-02,  1.1315e-02,  3.6405e-02, -1.5163e-02,\n",
              "            2.3544e-02, -4.4526e-02,  4.3570e-02],\n",
              "          [-2.5711e-02,  4.0584e-02,  3.3374e-02,  3.4601e-03, -4.2974e-02,\n",
              "           -3.5979e-02, -3.8622e-02, -7.1656e-03, -3.2187e-02,  3.4314e-02,\n",
              "            4.9540e-02, -1.6837e-03, -4.4790e-02, -2.4792e-02, -2.2903e-02,\n",
              "           -4.1168e-02, -6.6185e-03,  3.4845e-03,  4.4103e-02, -1.4742e-02,\n",
              "           -1.6126e-02,  3.1369e-02, -3.5286e-02, -3.9850e-02, -4.2428e-02,\n",
              "           -4.9056e-02,  2.1846e-03, -2.2378e-02],\n",
              "          [-2.0936e-02,  2.6329e-02,  4.5960e-02, -2.5477e-02, -1.7220e-03,\n",
              "            3.2488e-02,  2.5155e-02,  2.4653e-02,  2.6980e-02, -2.6038e-02,\n",
              "            3.7335e-03, -2.4599e-02,  1.3199e-02,  2.8851e-04,  4.7070e-02,\n",
              "            4.6869e-02,  2.5923e-02,  4.5200e-02,  3.0450e-02, -4.8768e-02,\n",
              "           -3.2324e-02, -1.3728e-02,  1.8831e-02,  2.7344e-02, -4.6266e-02,\n",
              "            2.8264e-02, -3.4091e-02, -2.3333e-02],\n",
              "          [-3.1551e-03, -2.2705e-02,  3.9546e-02,  3.7086e-02, -2.0277e-02,\n",
              "           -4.5876e-03, -4.6799e-02, -3.1607e-02,  4.8617e-02,  4.3220e-02,\n",
              "           -2.5323e-02,  4.3714e-02, -3.8481e-03,  2.4377e-02,  2.3277e-02,\n",
              "           -6.3961e-03, -1.5350e-02,  2.7863e-02, -2.1927e-03,  4.0122e-02,\n",
              "           -3.5276e-02,  1.2083e-02, -4.3005e-02,  2.1518e-02,  4.1627e-02,\n",
              "            1.0169e-02,  4.8076e-02,  1.8472e-02],\n",
              "          [-4.9460e-02, -1.7052e-02,  1.7771e-04, -1.8340e-03, -7.8268e-03,\n",
              "           -4.5513e-02, -5.3365e-05, -4.0843e-02,  1.1758e-02, -2.7820e-02,\n",
              "           -3.5451e-02,  3.0428e-02, -7.6213e-03,  1.3873e-02,  2.8909e-02,\n",
              "            1.3967e-02, -4.8589e-02, -2.5149e-02, -3.9609e-02, -1.2083e-02,\n",
              "            3.7977e-02, -3.5715e-02,  1.0352e-02, -3.4857e-02, -2.3637e-02,\n",
              "           -4.3129e-02, -4.3643e-02, -2.9939e-02],\n",
              "          [ 3.6835e-02, -2.6917e-02,  3.5770e-02, -1.6133e-02,  4.8577e-02,\n",
              "            6.4828e-03, -1.1258e-02, -4.3020e-02, -1.5395e-02,  3.1655e-02,\n",
              "           -1.9980e-02, -7.6610e-03, -1.9760e-02, -1.2078e-02, -4.7620e-02,\n",
              "           -7.4258e-03,  1.6152e-02,  1.2539e-02, -3.1185e-02,  4.0089e-02,\n",
              "            1.1010e-02,  1.6003e-04, -3.4731e-02,  2.6069e-02,  4.0122e-02,\n",
              "           -2.2680e-02,  3.5857e-03, -1.3768e-02],\n",
              "          [-2.8982e-02,  2.5182e-02, -3.8843e-02,  2.2008e-02,  1.0367e-03,\n",
              "            1.9185e-02,  4.9392e-02,  5.6082e-03, -4.3335e-02, -4.6108e-02,\n",
              "            3.0005e-02, -4.7909e-02,  2.8021e-02,  3.9388e-02,  1.0394e-02,\n",
              "           -2.7798e-02, -6.6539e-03,  3.5516e-02, -4.1434e-02,  3.4643e-02,\n",
              "            2.7305e-02,  1.3558e-02,  4.4148e-02,  2.4413e-02,  1.9511e-02,\n",
              "            2.7306e-02,  4.3369e-02,  1.0839e-02],\n",
              "          [-2.8667e-02, -3.4883e-02,  3.4020e-02, -3.6590e-02, -3.8270e-02,\n",
              "            4.2388e-02,  3.1572e-01,  7.1119e-01,  6.2499e-01,  6.3288e-01,\n",
              "            2.1791e-01,  1.1400e-01,  4.4906e-02, -1.3141e-02,  6.5906e-03,\n",
              "           -2.3902e-02, -3.7928e-02,  4.3826e-02, -1.2989e-02, -3.1891e-02,\n",
              "            5.3105e-03, -3.3556e-02,  2.5900e-02,  9.7234e-03, -2.8108e-02,\n",
              "            2.4982e-02, -2.7598e-02,  1.8728e-02],\n",
              "          [ 1.6545e-02,  3.3946e-02,  1.1745e-03, -4.4224e-02,  1.7818e-02,\n",
              "            1.0498e-02,  8.4641e-01,  1.0416e+00,  9.4977e-01,  9.5328e-01,\n",
              "            9.7496e-01,  9.2748e-01,  7.3875e-01,  8.0951e-01,  7.3273e-01,\n",
              "            8.0841e-01,  7.8890e-01,  7.6864e-01,  7.9104e-01,  7.4803e-01,\n",
              "            7.1620e-01,  2.0112e-01,  9.0481e-03, -2.0072e-02, -1.0210e-02,\n",
              "           -2.9008e-02,  4.9345e-02,  4.5458e-02],\n",
              "          [-2.5123e-02,  4.7511e-02, -2.4069e-02, -2.0652e-03,  9.8707e-03,\n",
              "           -4.7282e-02,  2.6555e-01,  4.8133e-01,  2.3685e-01,  4.4890e-01,\n",
              "            6.5991e-01,  8.4542e-01,  1.0145e+00,  8.5717e-01,  1.0057e+00,\n",
              "            9.6599e-01,  1.0037e+00,  1.0150e+00,  9.4587e-01,  1.0061e+00,\n",
              "            9.7307e-01,  5.3695e-01,  4.6432e-02, -3.5904e-02,  2.7621e-02,\n",
              "           -8.6689e-03, -4.1102e-02,  4.8973e-02],\n",
              "          [-1.9042e-02,  4.6931e-02, -5.3867e-04,  6.0538e-03,  3.2710e-02,\n",
              "           -3.2333e-02, -4.8760e-02,  3.8506e-02, -2.3829e-02, -1.8153e-02,\n",
              "            3.2417e-03,  8.8562e-02,  2.1674e-01,  6.4328e-02,  2.6662e-01,\n",
              "            2.4913e-01,  2.6098e-01,  2.6862e-01,  1.1201e-01,  9.1494e-01,\n",
              "            1.0259e+00,  4.2318e-01, -3.7650e-02, -1.2785e-02,  3.1052e-02,\n",
              "            2.3246e-02,  3.2110e-02,  1.7734e-03],\n",
              "          [-1.1706e-02, -2.8327e-02,  1.7490e-02, -4.3740e-02, -4.6245e-02,\n",
              "           -4.1896e-02, -1.7663e-02,  2.3788e-03, -4.2974e-02, -4.0297e-02,\n",
              "            6.6182e-03,  3.4057e-02, -2.8168e-02, -2.4882e-02, -1.2680e-02,\n",
              "           -1.8125e-02,  3.8908e-02,  3.2395e-02,  3.3263e-01,  9.7109e-01,\n",
              "            8.6395e-01,  1.1020e-01, -1.9458e-02, -4.2381e-02,  2.8631e-02,\n",
              "           -2.0717e-02,  3.9957e-02, -1.0568e-03],\n",
              "          [-4.0668e-02, -2.5613e-02,  5.1185e-03, -7.1374e-03,  4.6083e-02,\n",
              "            2.0309e-02,  3.6631e-02, -3.2036e-02, -4.7473e-02, -4.0481e-02,\n",
              "            3.4895e-02, -3.5468e-02, -2.3772e-02, -3.2806e-02, -8.6226e-03,\n",
              "            2.6234e-02, -4.7421e-02,  8.0923e-02,  9.2131e-01,  9.8794e-01,\n",
              "            2.8493e-01,  1.0250e-02, -3.1150e-03, -3.8554e-02,  1.7076e-02,\n",
              "            2.9884e-02,  3.1709e-02, -4.0978e-02],\n",
              "          [ 7.1962e-03,  2.0989e-02, -4.9346e-02,  8.6764e-03,  1.5208e-02,\n",
              "           -2.6884e-03,  3.2526e-02,  4.8169e-03,  1.5995e-02,  1.7732e-02,\n",
              "           -4.0442e-02,  2.1517e-03,  1.2926e-02,  2.8472e-02, -4.5370e-02,\n",
              "            3.3083e-02,  1.8858e-02,  5.0271e-01,  1.0286e+00,  9.7629e-01,\n",
              "            2.1123e-01,  2.8046e-02,  4.6444e-02,  2.0990e-02,  4.2649e-03,\n",
              "            9.9236e-03, -9.4314e-03, -4.1090e-02],\n",
              "          [ 1.7782e-03, -1.6606e-02, -4.7893e-02,  5.0810e-03,  2.6439e-02,\n",
              "            1.9782e-02,  4.2449e-02, -1.2568e-02, -1.6702e-02,  2.7739e-02,\n",
              "            1.6465e-03, -2.3105e-02, -1.1106e-02, -3.4342e-02, -8.5078e-03,\n",
              "           -4.3875e-02,  2.2231e-01,  1.0213e+00,  9.7994e-01,  1.9820e-01,\n",
              "            1.8010e-02, -2.4286e-02, -4.0959e-02, -2.1390e-03, -3.3304e-02,\n",
              "            3.9288e-02,  3.1158e-02, -3.2030e-02],\n",
              "          [-3.6158e-02,  3.0299e-02,  1.0844e-02,  8.3447e-03, -4.3829e-02,\n",
              "           -3.3850e-02, -4.3551e-02, -3.1458e-02, -1.4398e-02,  3.4780e-02,\n",
              "            4.8995e-02, -1.3507e-03, -3.3442e-03,  4.9461e-02, -2.0474e-02,\n",
              "           -4.4497e-02,  5.5300e-01,  1.0279e+00,  7.7664e-01,  2.8208e-02,\n",
              "            1.9649e-02,  4.0287e-02, -2.8200e-02,  3.8406e-02, -3.8321e-02,\n",
              "            3.5619e-02, -4.8703e-02,  2.4770e-03],\n",
              "          [-4.9487e-03,  2.2430e-02,  1.3674e-02,  1.9255e-02,  2.6008e-02,\n",
              "            6.2937e-03,  3.5911e-02, -4.2153e-02,  1.5931e-02, -2.0018e-02,\n",
              "            2.0973e-02, -1.3180e-02,  4.2290e-02, -2.1572e-02,  1.3431e-02,\n",
              "            1.0435e-02,  7.8278e-01,  9.2355e-01,  2.7092e-01, -2.3561e-03,\n",
              "            2.6980e-02,  3.8106e-02,  1.9847e-02,  2.7192e-02, -1.6447e-03,\n",
              "            3.3414e-02, -1.0800e-02,  1.0802e-03],\n",
              "          [-4.9539e-02, -3.5565e-02, -4.5660e-03,  1.0539e-02,  2.6010e-02,\n",
              "            9.0919e-03,  1.2949e-04,  1.6659e-02, -4.0498e-02, -3.4539e-02,\n",
              "           -4.0467e-02,  4.7598e-02,  1.7449e-02,  2.6927e-03, -3.7246e-02,\n",
              "            5.2179e-01,  9.4645e-01,  7.3142e-01,  4.0833e-02,  6.4610e-03,\n",
              "            4.9288e-02, -4.1673e-02,  1.0753e-03, -1.9534e-02,  3.7924e-02,\n",
              "           -1.6558e-02, -3.6798e-02,  4.4262e-02],\n",
              "          [ 1.7303e-03, -4.1801e-02,  4.1329e-02,  4.9690e-02, -2.4095e-02,\n",
              "            1.4741e-02, -2.8688e-03,  2.5627e-02,  1.4483e-03,  1.4883e-02,\n",
              "            4.7196e-02, -1.3003e-03,  1.8869e-02,  3.7431e-03,  2.8000e-01,\n",
              "            9.3574e-01,  9.0059e-01,  2.4866e-01,  3.2953e-02, -1.3418e-02,\n",
              "            3.7930e-02, -1.6651e-02, -4.9619e-02,  7.3182e-03, -1.8620e-02,\n",
              "            1.5370e-02,  2.7852e-02, -1.3271e-02],\n",
              "          [ 2.0463e-03,  2.3055e-02, -4.6644e-02, -9.0257e-03,  4.2344e-02,\n",
              "            2.1317e-02, -3.2285e-02, -4.1344e-02, -3.3026e-02, -2.8724e-04,\n",
              "           -2.3220e-02, -4.0445e-02, -1.2870e-02,  1.2242e-01,  8.6096e-01,\n",
              "            9.7829e-01,  6.5980e-01, -3.9408e-02,  2.2209e-02,  3.1487e-02,\n",
              "            4.9000e-02,  3.0018e-02,  1.9266e-02,  3.9169e-02, -1.5393e-02,\n",
              "           -4.2412e-02,  4.8345e-02, -3.8544e-02],\n",
              "          [ 2.2818e-02, -2.7662e-02, -3.8793e-02,  4.5000e-02, -4.4626e-02,\n",
              "           -2.0998e-02, -1.0244e-02,  9.3965e-03,  3.8667e-03,  2.8735e-02,\n",
              "           -1.4447e-02, -3.0685e-02,  1.0103e-02,  7.5629e-01,  9.9958e-01,\n",
              "            9.0535e-01,  1.7634e-01,  5.6994e-03,  1.6531e-02,  4.3234e-02,\n",
              "            1.7717e-02,  2.5880e-02, -4.5980e-02, -3.0198e-02, -1.5322e-03,\n",
              "            7.9252e-03,  1.8571e-02,  2.8486e-02],\n",
              "          [-3.2664e-02,  1.3027e-02,  1.8504e-02,  1.9064e-02,  2.0016e-04,\n",
              "            3.3821e-02,  1.7759e-02,  1.8618e-02,  2.2874e-02, -4.6264e-02,\n",
              "           -4.9623e-02,  1.1709e-02,  1.0065e-01,  9.6066e-01,  1.0279e+00,\n",
              "            3.1936e-01,  1.5526e-02, -7.9435e-03, -6.6233e-03, -3.5620e-02,\n",
              "            4.4986e-02,  3.6811e-02,  4.7340e-02,  2.1959e-02,  2.9783e-02,\n",
              "           -1.6746e-02, -3.0399e-02,  2.1141e-02],\n",
              "          [ 4.2831e-02, -2.9352e-03,  4.5555e-02,  1.9398e-02, -4.5484e-02,\n",
              "            1.3743e-02, -3.0018e-02, -4.0645e-02,  4.2467e-02,  2.3592e-02,\n",
              "           -4.3171e-02,  1.1444e-01,  8.5524e-01,  1.0302e+00,  4.5778e-01,\n",
              "           -5.3899e-03, -3.6567e-02,  2.2119e-03, -4.6343e-02,  9.9519e-03,\n",
              "           -3.9299e-03,  3.6466e-02,  1.2910e-02,  7.8796e-03,  4.6251e-02,\n",
              "            4.4360e-03,  3.8823e-02,  1.3024e-02],\n",
              "          [ 1.0809e-02, -4.4907e-02,  4.1644e-02, -2.9736e-03, -1.4718e-02,\n",
              "            4.1034e-02, -4.7550e-02, -9.2739e-03,  7.8740e-04,  7.5910e-03,\n",
              "           -2.6780e-02,  4.7355e-01,  9.9658e-01,  1.0354e+00,  2.1015e-01,\n",
              "           -2.8583e-02, -6.8975e-03, -4.9629e-03, -5.8861e-03,  2.1521e-02,\n",
              "            1.4907e-02, -4.8836e-02,  3.0034e-02, -3.9433e-02, -3.2930e-02,\n",
              "           -2.7460e-02,  3.7839e-02,  2.5908e-03],\n",
              "          [ 2.4338e-02,  1.0123e-02,  2.1730e-02,  2.5039e-02, -4.8449e-02,\n",
              "           -1.5617e-02,  3.5529e-02,  3.4008e-02, -1.9880e-02,  2.1416e-02,\n",
              "            2.4119e-01,  9.3271e-01,  9.9671e-01,  1.0226e+00,  1.5429e-01,\n",
              "            4.3925e-02, -3.5111e-02,  2.0935e-02, -3.4893e-02, -3.1352e-02,\n",
              "           -2.4895e-02,  1.3989e-02, -4.6692e-03,  2.9262e-02,  2.8049e-02,\n",
              "            4.4315e-02, -3.1400e-02,  3.9037e-02],\n",
              "          [ 1.6940e-02, -1.8738e-02,  3.8074e-02, -2.4387e-02, -4.7399e-03,\n",
              "            2.4673e-02, -3.1012e-02,  1.8463e-02,  2.6477e-02,  1.0301e-02,\n",
              "            5.1093e-01,  1.0011e+00,  9.8167e-01,  8.2079e-01,  1.6467e-01,\n",
              "           -2.1101e-02,  2.0894e-02, -3.7467e-02,  4.5839e-02,  1.0067e-02,\n",
              "           -9.0598e-03, -3.2603e-02,  4.1205e-02, -4.7556e-02,  3.0654e-02,\n",
              "            3.2878e-02, -3.6082e-02,  4.7424e-02],\n",
              "          [-1.3242e-02, -2.1140e-02, -4.3381e-02,  2.4391e-02, -1.0393e-02,\n",
              "            4.4416e-02, -3.5939e-02,  7.8962e-03,  2.2675e-02,  2.7322e-02,\n",
              "            4.7795e-01,  9.7627e-01,  8.3930e-01,  9.6780e-02, -3.5713e-02,\n",
              "           -3.9873e-02, -2.9714e-02,  3.3545e-02,  1.1160e-02,  3.9263e-02,\n",
              "            3.6847e-02, -2.5677e-02,  1.8961e-03, -4.5883e-03, -1.2024e-02,\n",
              "           -3.6025e-03,  1.0569e-02, -3.8507e-03],\n",
              "          [-4.4077e-02,  1.3521e-02,  6.7912e-03,  2.7252e-02,  2.0865e-02,\n",
              "            1.5179e-02,  2.6704e-02,  7.2973e-03, -1.2977e-02, -4.1283e-02,\n",
              "            2.6756e-02, -2.2844e-02,  4.7073e-02, -3.9926e-02, -3.1946e-02,\n",
              "            4.2963e-02,  2.8508e-02, -2.4963e-02, -3.9805e-03, -4.2205e-02,\n",
              "            4.5265e-02, -2.2839e-02,  1.7161e-02,  2.6426e-02, -5.5670e-03,\n",
              "           -7.6286e-03, -2.6585e-02,  6.6524e-03]]]], grad_fn=<AddBackward0>)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-B36Wu_bm_G",
        "outputId": "5cdbb3d1-7cd9-4fab-c2df-d9f8f770cbe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "\n",
        "# projecting the step\n",
        "delta = eps_step*torch.sign(x.grad)\n",
        "delta = torch.clamp(delta, min=-1*eps, max=eps)  \n",
        "# taking the step    \n",
        "x = x + delta\n",
        "# projecting the output to the [0,1] box\n",
        "x = torch.clamp(x, min=0, max=1)\n",
        "# check if we have an adversarial example \n",
        "out = model(x)\n",
        "pred = torch.max(out, dim=1)\n",
        "if pred!=label: return x"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-56a89bc979bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# projecting the step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meps_step\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# taking the step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sign(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lrK0p32bqx4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
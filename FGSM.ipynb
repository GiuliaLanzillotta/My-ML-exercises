{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM\n",
    "\n",
    "Here we're using targeted attacks to force a toy model into mistakes. As a targeted attack method we employ FGSM (fast gradient signed method), whose priority is speed (as the name suggests), definetly not optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1958029f210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the architecture. <br>\n",
    "Note that for the purpose of the exercise we don't actually need to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plain and simple ReLU network\n",
    "N = nn.Sequential(nn.Linear(10, 10, bias=False),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(10, 10, bias=False),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(10, 3, bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate an example\n",
    "x = torch.rand((1, 10)) # the first dimension is the batch size; the following dimensions the actual dimension of the data\n",
    "x.requires_grad_() # make sure we can compute the gradient w.r.t x\n",
    "t = 1 # target class (i.e. the class that we want to force the model to predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the noise level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsReal = 0.4 #depending on your data this might be large or small\n",
    "eps = epsReal - 1e-7 # small constant to offset floating-point erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Class:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Class: \", N(x).argmax(dim=1).item())\n",
    "assert(N(x).argmax(dim=1).item() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradient\n",
    "# note that CrossEntropyLoss() combines the cross-entropy loss and an implicit softmax function\n",
    "L = nn.CrossEntropyLoss()\n",
    "loss = L(N(x), torch.tensor([t], dtype=torch.long))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behinf FGSM is pretty simple: we'll perturbe the input on each dimension in the direction that minimizes the loss wrt to the target class, hoping to get into the new label area without actually going too far. Note however, that there is no control over the length of the movement in FGSM, hence we have no guarantees (other than the magnitude of the noise) on the level of distortion of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xBar = x - eps*torch.sign(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Class:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"New Class: \", N(xBar).argmax(dim=1).item())\n",
    "assert(N(xBar).argmax(dim=1).item() == 1)\n",
    "assert( torch.norm((x-xBar), p=float('inf')) <= epsReal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission accomplished! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
